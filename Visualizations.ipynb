{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5jMxRNZkIxOHVl+R2Dvlp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Experiment 1: Scaling Behavior — Single-Domain vs Multi-Domain Retrieval Across Backends**\n","\n","This section visualizes and analyzes retrieval performance for four vector-store backends (FAISS Single, FAISS Sharded, Chroma, and Spark) across three datastore sizes (10k, 30k, 50k).  \n","We compare:\n","- **Single-domain (Wiki) vs Multi-domain**\n","- **p50 and p90 retrieval latency**\n","- **Throughput (QPS) scaling**\n","- **Backend-wise performance differences**\n","\n","The goal is to evaluate how well each backend scales as the number of chunks increases, and how domain heterogeneity affects retrieval speed."],"metadata":{"id":"hz5j8w6nK1gr"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_88MG-tmHEu","executionInfo":{"status":"ok","timestamp":1765643836064,"user_tz":-330,"elapsed":122483,"user":{"displayName":"Shruti Jagdale","userId":"17369267178487205282"}},"outputId":"878accd5-0150-41f8-932c-62d9dd8e3753"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ============================\n","# 1. Mount Drive\n","# ============================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","# ============================\n","# 2. Imports\n","# ============================\n","import os\n","import json\n","import re\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","\n","# ============================\n","# 3. Set correct base directory\n","# ============================\n","BASE_DIR = \"/content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary\"\n","\n","\n","# ============================\n","# 4. Helper to find bench summary files\n","# ============================\n","def find_bench_summaries(base_dir: str):\n","    paths = []\n","    for root, _, files in os.walk(base_dir):\n","        for fn in files:\n","            if fn.endswith(\"_bench_summary.json\"):\n","                paths.append(os.path.join(root, fn))\n","    return sorted(paths)\n","\n","\n","# ============================\n","# 5. Parse filename (domain, backend, size)\n","# ============================\n","def parse_filename(path: str):\n","    name = os.path.basename(path)\n","    stem = name.replace(\"_bench_summary.json\", \"\")\n","    tokens = stem.split(\"_\")\n","\n","    domain = tokens[0]  # wiki or multidomain\n","\n","    # find size token SAFELY\n","    size_token = None\n","    for t in tokens:\n","        if t in (\"10k\", \"30k\", \"50k\"):\n","            size_token = t\n","            break\n","\n","    if size_token is None:\n","        raise ValueError(f\"Cannot find size (10k/30k/50k) in filename: {name}\")\n","\n","    size_map = {\"10k\": 10000, \"30k\": 30000, \"50k\": 50000}\n","    size = size_map[size_token]\n","    size_k = size // 1000\n","\n","    # backend between domain and size (skip 'llm')\n","    idx_size = tokens.index(size_token)\n","    backend_tokens = [t for t in tokens[1:idx_size] if t != \"llm\"]\n","    backend = \"_\".join(backend_tokens)\n","\n","    return {\n","        \"filename\": name,\n","        \"path\": path,\n","        \"domain\": domain,\n","        \"backend\": backend,\n","        \"size\": size,\n","        \"size_k\": size_k,\n","        \"size_label\": size_token,\n","    }\n","\n","\n","# ============================\n","# 6. Load all JSON files\n","# ============================\n","paths = find_bench_summaries(BASE_DIR)\n","print(\"Found bench_summary files:\", len(paths))\n","for p in paths:\n","    print(\"  \", p)\n","\n","rows = []\n","for path in paths:\n","    meta = parse_filename(path)\n","\n","    with open(path, \"r\") as f:\n","        js = json.load(f)\n","\n","    meta.update({\n","        \"retrieval_avg_ms\": js.get(\"avg_ms\"),\n","        \"retrieval_p50_ms\": js.get(\"p50_ms\"),\n","        \"retrieval_p90_ms\": js.get(\"p90_ms\"),\n","        \"qps\": js.get(\"qps\"),\n","        \"llm_avg_ms\": js.get(\"llm_avg_ms\"),\n","        \"llm_p50_ms\": js.get(\"llm_p50_ms\"),\n","        \"llm_p95_ms\": js.get(\"llm_p95_ms\"),\n","        \"llm_qps\": js.get(\"llm_qps\"),\n","    })\n","\n","    rows.append(meta)\n","\n","df = pd.DataFrame(rows).sort_values([\"domain\", \"backend\", \"size\"])\n","df.reset_index(drop=True, inplace=True)\n","\n","df"],"metadata":{"id":"Hvfff1FZmSdE","outputId":"08d568a4-6511-4ee4-881e-e9b5e2c428f2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found bench_summary files: 24\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_chroma_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_chroma_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_chroma_50k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_sharded_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_sharded_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_sharded_50k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_single_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_single_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_single_50k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_spark_10k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_spark_30k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_spark_50k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_chroma_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_chroma_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_chroma_50k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_sharded_10k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_sharded_30k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_sharded_50k_llm_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_single_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_single_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_faiss_single_50k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_spark_10k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_spark_30k_bench_summary.json\n","   /content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/wiki_spark_50k_bench_summary.json\n"]}]},{"cell_type":"code","source":["# ============================\n","# Plotting utilities\n","# ============================\n","\n","BACKEND_LABELS = {\n","    \"faiss_single\": \"FAISS (Single)\",\n","    \"faiss_sharded\": \"FAISS (Sharded)\",\n","    \"chroma\": \"Chroma\",\n","    \"spark\": \"Spark\",\n","}\n","\n","DOMAIN_LABELS = {\n","    \"wiki\": \"Wiki (Single-domain)\",\n","    \"multidomain\": \"Multi-domain\",\n","}\n","\n","\n","def plot_retrieval_latency(df, metric=\"retrieval_p50_ms\"):\n","    for domain in [\"wiki\", \"multidomain\"]:\n","        sub = df[df[\"domain\"] == domain]\n","\n","        plt.figure()\n","        for backend, grp in sub.groupby(\"backend\"):\n","            grp = grp.sort_values(\"size_k\")\n","            plt.plot(\n","                grp[\"size_k\"],\n","                grp[metric],\n","                marker=\"o\",\n","                label=BACKEND_LABELS.get(backend, backend),\n","            )\n","\n","        plt.title(f\"{DOMAIN_LABELS[domain]} – {metric}\")\n","        plt.xlabel(\"Datastore size (k chunks)\")\n","        plt.ylabel(metric + \" (ms)\")\n","        plt.grid(True, alpha=0.3)\n","        plt.legend()\n","        plt.show()\n","\n","\n","def plot_qps(df):\n","    for domain in [\"wiki\", \"multidomain\"]:\n","        sub = df[df[\"domain\"] == domain]\n","\n","        plt.figure()\n","        for backend, grp in sub.groupby(\"backend\"):\n","            grp = grp.sort_values(\"size_k\")\n","            plt.plot(\n","                grp[\"size_k\"],\n","                grp[\"qps\"],\n","                marker=\"o\",\n","                label=BACKEND_LABELS.get(backend, backend),\n","            )\n","\n","        plt.title(f\"{DOMAIN_LABELS[domain]} – Retrieval QPS\")\n","        plt.xlabel(\"Datastore size (k chunks)\")\n","        plt.ylabel(\"QPS\")\n","        plt.grid(True, alpha=0.3)\n","        plt.legend()\n","        plt.show()\n","\n","\n","def plot_domain_comparison(df, backend=\"faiss_single\", metric=\"retrieval_p50_ms\"):\n","    sub = df[df[\"backend\"] == backend]\n","\n","    plt.figure()\n","    for domain, grp in sub.groupby(\"domain\"):\n","        grp = grp.sort_values(\"size_k\")\n","        plt.plot(\n","            grp[\"size_k\"],\n","            grp[metric],\n","            marker=\"o\",\n","            label=DOMAIN_LABELS.get(domain, domain),\n","        )\n","\n","    plt.title(f\"{BACKEND_LABELS.get(backend, backend)} – {metric} (Wiki vs Multidomain)\")\n","    plt.xlabel(\"Datastore size (k chunks)\")\n","    plt.ylabel(metric + \" (ms)\")\n","    plt.grid(True, alpha=0.3)\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"2V2FL8-OIYfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieval latency vs size (p50 and p90)\n","plot_retrieval_latency(df, metric=\"retrieval_p50_ms\")\n","plot_retrieval_latency(df, metric=\"retrieval_p90_ms\")\n","\n","# QPS vs size\n","plot_qps(df)\n","\n","# Direct single vs multi-domain comparison per backend (p50)\n","plot_domain_comparison(df, backend=\"faiss_single\", metric=\"retrieval_p50_ms\")\n","plot_domain_comparison(df, backend=\"faiss_sharded\", metric=\"retrieval_p50_ms\")\n","plot_domain_comparison(df, backend=\"chroma\", metric=\"retrieval_p50_ms\")\n","plot_domain_comparison(df, backend=\"spark\", metric=\"retrieval_p50_ms\")"],"metadata":{"id":"dD-lrRIeJtb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combined Summary Visualization — Experiment 1 (Single-domain vs Multi-domain)\n","\n","import matplotlib.pyplot as plt\n","\n","# Ensure consistent ordering\n","backends_order = [\"faiss_single\", \"faiss_sharded\", \"chroma\", \"spark\"]\n","backend_labels = {\n","    \"faiss_single\": \"FAISS (Single)\",\n","    \"faiss_sharded\": \"FAISS (Sharded)\",\n","    \"chroma\": \"Chroma\",\n","    \"spark\": \"Spark\"\n","}\n","\n","colors = {\n","    \"faiss_single\": \"#2ca02c\",\n","    \"faiss_sharded\": \"#ff7f0e\",\n","    \"chroma\": \"#1f77b4\",\n","    \"spark\": \"#d62728\"\n","}\n","\n","fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n","fig.suptitle(\"Experiment 1 Summary — Single-domain vs Multi-domain Scaling\", fontsize=18, fontweight=\"bold\")\n","\n","\n","# =============================\n","# 1. p50 Latency (Wiki)\n","# =============================\n","ax = axs[0, 0]\n","sub = df[df[\"domain\"] == \"wiki\"]\n","\n","for backend in backends_order:\n","    grp = sub[sub[\"backend\"] == backend].sort_values(\"size_k\")\n","    ax.plot(grp[\"size_k\"], grp[\"retrieval_p50_ms\"], marker=\"o\", label=backend_labels[backend], color=colors[backend])\n","\n","ax.set_title(\"Wiki (Single-domain) — p50 Retrieval Latency\")\n","ax.set_xlabel(\"Datastore size (k chunks)\")\n","ax.set_ylabel(\"Latency (ms)\")\n","ax.grid(True, alpha=0.3)\n","ax.legend()\n","\n","\n","# =============================\n","# 2. p50 Latency (Multidomain)\n","# =============================\n","ax = axs[0, 1]\n","sub = df[df[\"domain\"] == \"multidomain\"]\n","\n","for backend in backends_order:\n","    grp = sub[sub[\"backend\"] == backend].sort_values(\"size_k\")\n","    ax.plot(grp[\"size_k\"], grp[\"retrieval_p50_ms\"], marker=\"o\", label=backend_labels[backend], color=colors[backend])\n","\n","ax.set_title(\"Multidomain — p50 Retrieval Latency\")\n","ax.set_xlabel(\"Datastore size (k chunks)\")\n","ax.set_ylabel(\"Latency (ms)\")\n","ax.grid(True, alpha=0.3)\n","\n","\n","# =============================\n","# 3. QPS (Wiki vs Multidomain — FAISS Single)\n","# =============================\n","ax = axs[1, 0]\n","for domain in [\"wiki\", \"multidomain\"]:\n","    grp = df[(df[\"backend\"] == \"faiss_single\") & (df[\"domain\"] == domain)].sort_values(\"size_k\")\n","    ax.plot(grp[\"size_k\"], grp[\"qps\"], marker=\"o\", label=(\"Wiki\" if domain==\"wiki\" else \"Multidomain\"))\n","\n","ax.set_title(\"FAISS Single — QPS Comparison\")\n","ax.set_xlabel(\"Datastore size (k chunks)\")\n","ax.set_ylabel(\"QPS\")\n","ax.grid(True, alpha=0.3)\n","ax.legend()\n","\n","\n","# =============================\n","# 4. Combined Domain Gap (p50 Latency)\n","# =============================\n","ax = axs[1, 1]\n","\n","for backend in backends_order:\n","    wiki_grp = df[(df[\"backend\"] == backend) & (df[\"domain\"] == \"wiki\")].sort_values(\"size_k\")\n","    multi_grp = df[(df[\"backend\"] == backend) & (df[\"domain\"] == \"multidomain\")].sort_values(\"size_k\")\n","\n","    ax.plot(wiki_grp[\"size_k\"], wiki_grp[\"retrieval_p50_ms\"],\n","            marker=\"o\", linestyle=\"-\", color=colors[backend], label=f\"{backend_labels[backend]} (Wiki)\")\n","\n","    ax.plot(multi_grp[\"size_k\"], multi_grp[\"retrieval_p50_ms\"],\n","            marker=\"x\", linestyle=\"--\", color=colors[backend], label=f\"{backend_labels[backend]} (Multi)\")\n","\n","ax.set_title(\"p50 Latency Gap — Wiki vs Multidomain\")\n","ax.set_xlabel(\"Datastore size (k chunks)\")\n","ax.set_ylabel(\"Latency (ms)\")\n","ax.grid(True, alpha=0.3)\n","ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n","\n","\n","plt.tight_layout(rect=[0, 0, 1, 0.97])\n","plt.show()"],"metadata":{"id":"oPksXVWlLp0F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Conclusion: Key Findings from Experiment 1**\n","\n","- **FAISS (Single & Sharded) shows excellent scalability**  \n","  Retrieval latency stays low (~11–14 ms) across all dataset sizes and both domains.  \n","  Domain heterogeneity (multi-domain) only slightly increases latency.\n","\n","- **Chroma also maintains stable performance**  \n","  Latency remains consistent (~12–14 ms) with small fluctuations.  \n","  Scaling from 10k → 50k does not degrade performance significantly.\n","\n","- **Spark performs poorly for real-time retrieval**  \n","  Retrieval latency is extremely high (18–28 seconds).  \n","  Throughput is effectively zero, confirming Spark is not built for low-latency vector search.\n","\n","- **Single-domain datasets are slightly faster than multi-domain**  \n","  Particularly visible in FAISS Single and Chroma, where multi-domain introduces small overhead.  \n","  This indicates embedding heterogeneity increases search complexity slightly.\n","\n","- **QPS results reinforce backend differences**  \n","  FAISS and Chroma support high throughput (40–80 QPS), while Spark collapses to near-zero QPS.\n","\n","- **Overall takeaway**  \n","  - FAISS is the **most robust and scalable** backend across domains and dataset sizes.  \n","  - Chroma performs well and consistently but slightly slower.  \n","  - Spark is unsuitable for interactive retrieval workloads.  \n","  - Multi-domain scaling is successful — latency remains stable and predictable even as data diversity grows."],"metadata":{"id":"-wP7WMsMLIgq"}},{"cell_type":"markdown","source":["## **Experiment 2: Large LLM without RAG vs Small LLM with RAG**\n","\n","This experiment compares a **small 1.1B LLM with RAG** (TinyLlama + multidomain 50k datastore) against a **larger standalone LLM without RAG**.  \n","The goal is to see whether a small model, paired with a retrieval datastore, can match or outperform a much larger model on **latency** and **throughput**, while keeping retrieval cost low.\n","\n","We reuse the **multidomain 50k** bench summary from Experiment 1 for the “Small + RAG” system, and load a separate bench summary generated by the `llm_no_RAG.py` script for the Large LLM baseline.  \n","The code below builds a comparison table and simple bar plots for:\n","\n","- p50 / average end-to-end latency (ms)  \n","- QPS (queries per second)  \n","- (optionally) tokens/sec if present in the big-LLM summary."],"metadata":{"id":"fKPnbY-XR0Gl"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import numpy as np\n","\n","# Paths\n","SMALL_RAG_PATH = \"/content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/multidomain_faiss_single_50k_bench_summary.json\"\n","BIG_NO_RAG_PATH = \"/content/drive/MyDrive/AMS 560 PROJECT VIZ/results/bench_summary/llm_only_summary.json\"\n","\n","def load_summary(path):\n","    with open(path, \"r\") as f:\n","        return json.load(f)\n","\n","small_js = load_summary(SMALL_RAG_PATH)\n","big_js   = load_summary(BIG_NO_RAG_PATH)\n","\n","print(\"Small + RAG summary:\", small_js)\n","print(\"Big LLM (no RAG) summary:\", big_js)\n","\n","# compute QPS for big model from raw_times_ms\n","big_total_ms = sum(big_js[\"raw_times_ms\"])\n","big_qps = big_js[\"n_queries\"] / (big_total_ms / 1000.0)   # queries per second\n","\n","rows = []\n","\n","# Small + RAG\n","rows.append({\n","    \"system\": \"Small LLM (1.1B) + RAG (50k)\",\n","    \"type\": \"small+rag\",\n","    \"lat_p50_ms\": small_js.get(\"llm_p50_ms\", small_js.get(\"p50_ms\")),\n","    \"lat_avg_ms\": small_js.get(\"llm_avg_ms\", small_js.get(\"avg_ms\")),\n","    \"qps\":        small_js.get(\"llm_qps\", small_js.get(\"qps\")),\n","    \"retrieval_p50_ms\": small_js.get(\"p50_ms\"),\n","    \"retrieval_avg_ms\": small_js.get(\"avg_ms\"),\n","})\n","\n","# Big LLM only\n","rows.append({\n","    \"system\": \"Big LLM (No RAG)\",\n","    \"type\": \"big_no_rag\",\n","    \"lat_p50_ms\": big_js.get(\"p50_ms\"),\n","    \"lat_avg_ms\": big_js.get(\"avg_ms\"),\n","    \"qps\":        big_qps,\n","    \"retrieval_p50_ms\": np.nan,   # no retrieval stage\n","    \"retrieval_avg_ms\": np.nan,\n","})\n","\n","exp2_df = pd.DataFrame(rows)\n","exp2_df"],"metadata":{"id":"GJtq3KE6WorA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 3, 1)\n","plt.bar(exp2_df[\"system\"], exp2_df[\"lat_p50_ms\"])\n","plt.title(\"End-to-end p50 Latency\")\n","plt.ylabel(\"Latency (ms)\")\n","plt.xticks(rotation=20)\n","plt.grid(axis=\"y\", alpha=0.3)\n","\n","plt.subplot(1, 3, 2)\n","plt.bar(exp2_df[\"system\"], exp2_df[\"lat_avg_ms\"])\n","plt.title(\"End-to-end Avg Latency\")\n","plt.ylabel(\"Latency (ms)\")\n","plt.xticks(rotation=20)\n","plt.grid(axis=\"y\", alpha=0.3)\n","\n","plt.subplot(1, 3, 3)\n","plt.bar(exp2_df[\"system\"], exp2_df[\"qps\"])\n","plt.title(\"Throughput (QPS)\")\n","plt.ylabel(\"Queries per second\")\n","plt.xticks(rotation=20)\n","plt.grid(axis=\"y\", alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"DxGpgh3saf7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Experiment 2 Conclusion**\n","\n","- The small 1.1B model with RAG (TinyLlama + 50k multidomain index) has end-to-end latency around **11.5–11.6 seconds per query**, mainly dominated by slow LLM decoding.\n","- The large standalone LLM without RAG answers in about **1.2–1.3 seconds per query**, achieving **~0.78 QPS**, roughly **9–10× faster** than the small + RAG system.\n","- Retrieval itself is cheap (≈12–13 ms), but in this setup the small model is not efficient enough to compensate for its size advantage.\n","- This suggests that, with the current models and infrastructure, a **well-optimized larger LLM without RAG can outperform a slow small-LLM+RAG stack on latency and throughput**, even though RAG may still help with grounding and knowledge freshness."],"metadata":{"id":"4RHX56P5gKWP"}},{"cell_type":"code","source":[],"metadata":{"id":"4fAE9Z-laUeC"},"execution_count":null,"outputs":[]}]}